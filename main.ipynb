{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jirSbgCFj-hZ"
      },
      "outputs": [],
      "source": [
        "# -----------------------\n",
        "# Imports\n",
        "# -----------------------\n",
        "import os\n",
        "import sys\n",
        "import warnings\n",
        "from typing import Dict\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import (\n",
        "    train_test_split,\n",
        "    cross_val_score,\n",
        "    KFold,\n",
        "    GridSearchCV,\n",
        "    RandomizedSearchCV,\n",
        ")\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score,\n",
        "    confusion_matrix,\n",
        "    ConfusionMatrixDisplay,\n",
        ")\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from joblib import dump\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "sns.set(style=\"whitegrid\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "94Y0Gs12lGp5"
      },
      "outputs": [],
      "source": [
        "# -----------------------\n",
        "# CONFIG\n",
        "# -----------------------\n",
        "CONFIG = {\n",
        "    \"DATA_PATH\": \"Training.csv\",\n",
        "    \"TARGET_COL\": \"prognosis\",\n",
        "    \"TEST_SIZE\": 0.2,\n",
        "    \"RANDOM_STATE\": 42,\n",
        "    \"OUTPUT_DIR\": \"outputs\",\n",
        "    \"EDA_DIR\": \"outputs/eda\",\n",
        "    \"MODEL_DIR\": \"outputs/models\",\n",
        "    \"PRED_DIR\": \"outputs/predictions\",\n",
        "    \"CM_DIR\": \"outputs/confusion_matrices\",\n",
        "    \"CV_FOLDS\": 5,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "T-9OOMNplBwd"
      },
      "outputs": [],
      "source": [
        "# -----------------------\n",
        "# Create Output Folders\n",
        "# -----------------------\n",
        "for d in (\n",
        "    CONFIG[\"OUTPUT_DIR\"],\n",
        "    CONFIG[\"EDA_DIR\"],\n",
        "    CONFIG[\"MODEL_DIR\"],\n",
        "    CONFIG[\"PRED_DIR\"],\n",
        "    CONFIG[\"CM_DIR\"],\n",
        "):\n",
        "    os.makedirs(d, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "O9wRklM_lNuN"
      },
      "outputs": [],
      "source": [
        "# -----------------------\n",
        "# Utils\n",
        "# -----------------------\n",
        "def load_data(path: str) -> pd.DataFrame:\n",
        "    print(f\"[INFO] Loading data from: {path}\")\n",
        "    if path.lower().endswith((\".xls\", \".xlsx\")):\n",
        "        df = pd.read_excel(path)\n",
        "    else:\n",
        "        df = pd.read_csv(path)\n",
        "    print(f\"[INFO] Loaded shape: {df.shape}\")\n",
        "    return df\n",
        "\n",
        "\n",
        "def quick_review(df: pd.DataFrame) -> None:\n",
        "    print(\"\\n[REVIEW] Head:\\n\", df.head())\n",
        "    print(\"\\n[REVIEW] Info:\")\n",
        "    print(df.info())\n",
        "    print(\"\\n[REVIEW] Missing values:\\n\", df.isnull().sum().sort_values(ascending=False).head(20))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "IkUHXG8HlRjy"
      },
      "outputs": [],
      "source": [
        "# -----------------------\n",
        "# Data Cleaning\n",
        "# -----------------------\n",
        "def clean_data(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    print(\"[CLEAN] Dropping fully empty columns...\")\n",
        "    df = df.dropna(axis=1, how=\"all\")\n",
        "    for col in df.columns:\n",
        "        if df[col].dtype in [np.float64, np.int64]:\n",
        "            df[col] = df[col].fillna(df[col].mean())\n",
        "        else:\n",
        "            df[col] = df[col].fillna(df[col].mode()[0] if not df[col].mode().empty else \"missing\")\n",
        "    print(\"[CLEAN] After cleaning, shape:\", df.shape)\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8_bYzpDmlXoX"
      },
      "outputs": [],
      "source": [
        "# -----------------------\n",
        "# EDA\n",
        "# -----------------------\n",
        "def run_eda(df: pd.DataFrame):\n",
        "    print(\"[EDA] Running exploratory data analysis...\")\n",
        "\n",
        "    # Target distribution\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    sns.countplot(y=df[CONFIG[\"TARGET_COL\"]], order=df[CONFIG[\"TARGET_COL\"]].value_counts().index)\n",
        "    plt.title(\"Target Distribution\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(CONFIG[\"EDA_DIR\"], \"target_distribution.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # Correlation heatmap for numeric features\n",
        "    num_df = df.select_dtypes(include=[\"int64\", \"float64\"])\n",
        "    if not num_df.empty:\n",
        "        plt.figure(figsize=(12, 10))\n",
        "        sns.heatmap(num_df.corr(), cmap=\"coolwarm\", center=0)\n",
        "        plt.title(\"Correlation Heatmap\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(CONFIG[\"EDA_DIR\"], \"correlation_heatmap.png\"))\n",
        "        plt.close()\n",
        "\n",
        "    print(\"[EDA] Plots saved to:\", CONFIG[\"EDA_DIR\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "M5w8B4oYlcGj"
      },
      "outputs": [],
      "source": [
        "# -----------------------\n",
        "# Preprocessing pipeline\n",
        "# -----------------------\n",
        "def build_preprocessing_pipeline(df):\n",
        "    feature_df = df.drop(CONFIG[\"TARGET_COL\"], axis=1, errors=\"ignore\")\n",
        "    num_cols = feature_df.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
        "    cat_cols = feature_df.select_dtypes(include=[\"object\"]).columns.tolist()\n",
        "\n",
        "    transformers = []\n",
        "    if num_cols:\n",
        "        transformers.append((\"num\", Pipeline([\n",
        "            (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
        "            (\"scaler\", StandardScaler())\n",
        "        ]), num_cols))\n",
        "    if cat_cols:\n",
        "        transformers.append((\"cat\", Pipeline([\n",
        "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "            (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True))\n",
        "        ]), cat_cols))\n",
        "\n",
        "    return ColumnTransformer(transformers=transformers), num_cols, cat_cols\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "c_pGMDLYlkcY"
      },
      "outputs": [],
      "source": [
        "# -----------------------\n",
        "# Model Evaluation\n",
        "# -----------------------\n",
        "def evaluate_model(y_true, y_pred, y_proba=None) -> Dict[str, float]:\n",
        "    metrics = {\n",
        "        \"accuracy\": float(accuracy_score(y_true, y_pred)),\n",
        "        \"precision\": float(precision_score(y_true, y_pred, average=\"weighted\", zero_division=0)),\n",
        "        \"recall\": float(recall_score(y_true, y_pred, average=\"weighted\", zero_division=0)),\n",
        "        \"f1\": float(f1_score(y_true, y_pred, average=\"weighted\", zero_division=0)),\n",
        "    }\n",
        "    if y_proba is not None:\n",
        "        try:\n",
        "            metrics[\"roc_auc\"] = float(roc_auc_score(y_true, y_proba, multi_class=\"ovr\"))\n",
        "        except Exception:\n",
        "            metrics[\"roc_auc\"] = np.nan\n",
        "    return metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jlJ_SHaQllUx"
      },
      "outputs": [],
      "source": [
        "\n",
        "# -----------------------\n",
        "# Confusion Matrix\n",
        "# -----------------------\n",
        "def plot_confusion_matrix(y_true, y_pred, class_names, model_name):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
        "    fig, ax = plt.subplots(figsize=(10, 8))\n",
        "    disp.plot(ax=ax, cmap=\"Blues\", values_format=\"d\", xticks_rotation=45)\n",
        "    plt.title(f\"Confusion Matrix - {model_name}\")\n",
        "    plt.tight_layout()\n",
        "    save_path = os.path.join(CONFIG[\"CM_DIR\"], f\"confusion_matrix_{model_name}.png\")\n",
        "    plt.savefig(save_path)\n",
        "    plt.close()\n",
        "    print(f\"[PLOT] Confusion matrix saved: {save_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "51XpgHh6llnr"
      },
      "outputs": [],
      "source": [
        "\n",
        "# -----------------------\n",
        "# Baseline & Comparison\n",
        "# -----------------------\n",
        "\n",
        "def baseline_and_compare(df, target, preprocessor):\n",
        "    X = df.drop(columns=[target])\n",
        "    y = df[target]\n",
        "\n",
        "    le = LabelEncoder()\n",
        "    y_encoded = le.fit_transform(y)\n",
        "    class_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y_encoded, test_size=CONFIG[\"TEST_SIZE\"],\n",
        "        random_state=CONFIG[\"RANDOM_STATE\"], stratify=y_encoded\n",
        "    )\n",
        "\n",
        "    models = {\n",
        "        \"RandomForest\": RandomForestClassifier(n_estimators=100, random_state=CONFIG[\"RANDOM_STATE\"]),\n",
        "        \"DecisionTree\": DecisionTreeClassifier(random_state=CONFIG[\"RANDOM_STATE\"]),\n",
        "        \"LogisticRegression\": LogisticRegression(max_iter=1000, random_state=CONFIG[\"RANDOM_STATE\"]),\n",
        "        \"SVM\": SVC(probability=True, random_state=CONFIG[\"RANDOM_STATE\"]),\n",
        "        \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric=\"mlogloss\", random_state=CONFIG[\"RANDOM_STATE\"]),\n",
        "    }\n",
        "\n",
        "    results, trained_pipelines = {}, {}\n",
        "\n",
        "    for name, model in models.items():\n",
        "        print(f\"\\n[MODEL] Training: {name}\")\n",
        "        pipe = Pipeline([(\"preprocessor\", preprocessor), (\"clf\", model)])\n",
        "        try:\n",
        "            cv = KFold(n_splits=CONFIG[\"CV_FOLDS\"], shuffle=True, random_state=CONFIG[\"RANDOM_STATE\"])\n",
        "            cv_scores = cross_val_score(pipe, X_train, y_train, cv=cv, scoring=\"accuracy\")\n",
        "        except Exception as e:\n",
        "            print(f\"[WARN] CV failed for {name}: {e}\")\n",
        "            cv_scores = [np.nan]\n",
        "\n",
        "        pipe.fit(X_train, y_train)\n",
        "        y_pred = pipe.predict(X_test)\n",
        "        # Confusion Matrix Plot\n",
        "        plot_confusion_matrix(y_test, y_pred, le.classes_, name)\n",
        "\n",
        "        try:\n",
        "            y_proba = pipe.predict_proba(X_test)\n",
        "        except Exception:\n",
        "            y_proba = None\n",
        "\n",
        "        metrics = evaluate_model(y_test, y_pred, y_proba)\n",
        "        print(f\"[RESULT] {name}: {metrics}\")\n",
        "\n",
        "        results[name] = {\"cv_mean\": np.nanmean(cv_scores), \"cv_std\": np.nanstd(cv_scores), \"test_metrics\": metrics}\n",
        "        trained_pipelines[name] = pipe\n",
        "        dump(pipe, os.path.join(CONFIG[\"MODEL_DIR\"], f\"{name}.joblib\"))\n",
        "\n",
        "    pd.Series(class_mapping).to_csv(os.path.join(CONFIG[\"OUTPUT_DIR\"], \"class_mapping.csv\"))\n",
        "\n",
        "    comp_df = pd.DataFrame([\n",
        "        {\"model\": k, \"cv_mean\": v[\"cv_mean\"], \"cv_std\": v[\"cv_std\"], **v[\"test_metrics\"]}\n",
        "        for k, v in results.items()\n",
        "    ]).sort_values(\"cv_mean\", ascending=False)\n",
        "\n",
        "    comp_df.to_csv(os.path.join(CONFIG[\"OUTPUT_DIR\"], \"model_comparison.csv\"), index=False)\n",
        "    print(\"[INFO] Model comparison saved.\")\n",
        "\n",
        "    # Auto-pick best\n",
        "    best_model_name = comp_df.loc[comp_df['cv_mean'].idxmax(), 'model']\n",
        "    print(f\"[AUTO] Best model selected: {best_model_name}\")\n",
        "    best_model = trained_pipelines[best_model_name]\n",
        "    dump(best_model, os.path.join(CONFIG[\"MODEL_DIR\"], \"best_model.joblib\"))\n",
        "    print(\"[AUTO] Best model saved as best_model.joblib\")\n",
        "\n",
        "    return best_model_name, best_model, (X_train, X_test, y_train, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "GpGe8rMEl3TI"
      },
      "outputs": [],
      "source": [
        "# -----------------------\n",
        "# Hyperparameter Tuning\n",
        "# -----------------------\n",
        "def tune_model(model_name, model, preprocessor, X_train, y_train):\n",
        "    print(f\"[TUNE] Hyperparameter tuning for {model_name}...\")\n",
        "\n",
        "    param_grids = {\n",
        "        \"DecisionTree\": {\"clf__max_depth\": [5, 10, 20, None], \"clf__min_samples_split\": [2, 5, 10]},\n",
        "        \"LogisticRegression\": {\"clf__C\": [0.1, 1, 10], \"clf__solver\": [\"liblinear\", \"lbfgs\"]},\n",
        "        \"SVM\": {\"clf__C\": [0.1, 1, 10], \"clf__kernel\": [\"linear\", \"rbf\"]},\n",
        "        \"RandomForest\": {\"clf__n_estimators\": [100, 200], \"clf__max_depth\": [None, 10, 20]},\n",
        "        \"XGBoost\": {\"clf__n_estimators\": [100, 200], \"clf__max_depth\": [3, 6, 10], \"clf__learning_rate\": [0.01, 0.1, 0.2]},\n",
        "    }\n",
        "\n",
        "    param_grid = param_grids.get(model_name, {})\n",
        "    pipe = Pipeline([(\"preprocessor\", preprocessor), (\"clf\", model)])\n",
        "\n",
        "    if param_grid:\n",
        "        random_search = RandomizedSearchCV(pipe, param_grid, cv=3, n_iter=5,\n",
        "                                           scoring=\"accuracy\", random_state=CONFIG[\"RANDOM_STATE\"], n_jobs=-1)\n",
        "        random_search.fit(X_train, y_train)\n",
        "        print(\"[TUNE] Best params (RandomizedSearchCV):\", random_search.best_params_)\n",
        "\n",
        "        grid_search = GridSearchCV(pipe, param_grid, cv=3, scoring=\"accuracy\", n_jobs=-1)\n",
        "        grid_search.fit(X_train, y_train)\n",
        "        print(\"[TUNE] Best params (GridSearchCV):\", grid_search.best_params_)\n",
        "        return grid_search.best_estimator_\n",
        "\n",
        "    else:\n",
        "        print(\"[TUNE] No tuning grid defined for this model.\")\n",
        "        return pipe\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5lfx0yyl7Z5",
        "outputId": "f12571e7-f09c-4ce7-e820-0822a29ab32e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Loading data from: Training.csv\n",
            "[INFO] Loaded shape: (4920, 134)\n",
            "[CLEAN] Dropping fully empty columns...\n",
            "[CLEAN] After cleaning, shape: (4920, 133)\n",
            "\n",
            "[REVIEW] Head:\n",
            "    itching  skin_rash  nodal_skin_eruptions  continuous_sneezing  shivering  \\\n",
            "0        1          1                     1                    0          0   \n",
            "1        0          1                     1                    0          0   \n",
            "2        1          0                     1                    0          0   \n",
            "3        1          1                     0                    0          0   \n",
            "4        1          1                     1                    0          0   \n",
            "\n",
            "   chills  joint_pain  stomach_pain  acidity  ulcers_on_tongue  ...  \\\n",
            "0       0           0             0        0                 0  ...   \n",
            "1       0           0             0        0                 0  ...   \n",
            "2       0           0             0        0                 0  ...   \n",
            "3       0           0             0        0                 0  ...   \n",
            "4       0           0             0        0                 0  ...   \n",
            "\n",
            "   blackheads  scurring  skin_peeling  silver_like_dusting  \\\n",
            "0           0         0             0                    0   \n",
            "1           0         0             0                    0   \n",
            "2           0         0             0                    0   \n",
            "3           0         0             0                    0   \n",
            "4           0         0             0                    0   \n",
            "\n",
            "   small_dents_in_nails  inflammatory_nails  blister  red_sore_around_nose  \\\n",
            "0                     0                   0        0                     0   \n",
            "1                     0                   0        0                     0   \n",
            "2                     0                   0        0                     0   \n",
            "3                     0                   0        0                     0   \n",
            "4                     0                   0        0                     0   \n",
            "\n",
            "   yellow_crust_ooze         prognosis  \n",
            "0                  0  Fungal infection  \n",
            "1                  0  Fungal infection  \n",
            "2                  0  Fungal infection  \n",
            "3                  0  Fungal infection  \n",
            "4                  0  Fungal infection  \n",
            "\n",
            "[5 rows x 133 columns]\n",
            "\n",
            "[REVIEW] Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4920 entries, 0 to 4919\n",
            "Columns: 133 entries, itching to prognosis\n",
            "dtypes: int64(132), object(1)\n",
            "memory usage: 5.0+ MB\n",
            "None\n",
            "\n",
            "[REVIEW] Missing values:\n",
            " itching                 0\n",
            "skin_rash               0\n",
            "nodal_skin_eruptions    0\n",
            "continuous_sneezing     0\n",
            "shivering               0\n",
            "chills                  0\n",
            "joint_pain              0\n",
            "stomach_pain            0\n",
            "acidity                 0\n",
            "ulcers_on_tongue        0\n",
            "muscle_wasting          0\n",
            "vomiting                0\n",
            "burning_micturition     0\n",
            "spotting_ urination     0\n",
            "fatigue                 0\n",
            "weight_gain             0\n",
            "anxiety                 0\n",
            "cold_hands_and_feets    0\n",
            "mood_swings             0\n",
            "weight_loss             0\n",
            "dtype: int64\n",
            "[EDA] Running exploratory data analysis...\n",
            "[EDA] Plots saved to: outputs/eda\n",
            "\n",
            "[MODEL] Training: RandomForest\n",
            "[PLOT] Confusion matrix saved: outputs/confusion_matrices/confusion_matrix_RandomForest.png\n",
            "[RESULT] RandomForest: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'roc_auc': 1.0}\n",
            "\n",
            "[MODEL] Training: DecisionTree\n",
            "[PLOT] Confusion matrix saved: outputs/confusion_matrices/confusion_matrix_DecisionTree.png\n",
            "[RESULT] DecisionTree: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'roc_auc': 1.0}\n",
            "\n",
            "[MODEL] Training: LogisticRegression\n",
            "[PLOT] Confusion matrix saved: outputs/confusion_matrices/confusion_matrix_LogisticRegression.png\n",
            "[RESULT] LogisticRegression: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'roc_auc': 1.0}\n",
            "\n",
            "[MODEL] Training: SVM\n",
            "[PLOT] Confusion matrix saved: outputs/confusion_matrices/confusion_matrix_SVM.png\n",
            "[RESULT] SVM: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'roc_auc': 1.0}\n",
            "\n",
            "[MODEL] Training: XGBoost\n",
            "[PLOT] Confusion matrix saved: outputs/confusion_matrices/confusion_matrix_XGBoost.png\n",
            "[RESULT] XGBoost: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'roc_auc': 1.0}\n",
            "[INFO] Model comparison saved.\n",
            "[AUTO] Best model selected: RandomForest\n",
            "[AUTO] Best model saved as best_model.joblib\n",
            "[TUNE] Hyperparameter tuning for RandomForest...\n",
            "[TUNE] Best params (RandomizedSearchCV): {'clf__n_estimators': 100, 'clf__max_depth': None}\n",
            "[TUNE] Best params (GridSearchCV): {'clf__max_depth': None, 'clf__n_estimators': 100}\n",
            "[FINAL] Tuned model saved as best_tuned_model.joblib\n"
          ]
        }
      ],
      "source": [
        "# -----------------------\n",
        "# Orchestrator\n",
        "# -----------------------\n",
        "def run_full_pipeline():\n",
        "    df = load_data(CONFIG[\"DATA_PATH\"])\n",
        "    if CONFIG[\"TARGET_COL\"] not in df.columns:\n",
        "        print(f\"[ERROR] Target col '{CONFIG['TARGET_COL']}' not found.\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    df = clean_data(df)\n",
        "    quick_review(df)\n",
        "    run_eda(df)\n",
        "\n",
        "    preprocessor, _, _ = build_preprocessing_pipeline(df)\n",
        "    best_model_name, best_model, (X_train, X_test, y_train, y_test) = baseline_and_compare(df, CONFIG[\"TARGET_COL\"], preprocessor)\n",
        "\n",
        "    tuned_model = tune_model(best_model_name, best_model.named_steps[\"clf\"], preprocessor, X_train, y_train)\n",
        "    dump(tuned_model, os.path.join(CONFIG[\"MODEL_DIR\"], \"best_tuned_model.joblib\"))\n",
        "    print(\"[FINAL] Tuned model saved as best_tuned_model.joblib\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_full_pipeline()\n",
        "# -----------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using model file: outputs/models/best_tuned_model.joblib\n",
            "Top Predictions:\n",
            "- Malaria: 54.00%\n",
            "- Jaundice: 18.00%\n",
            "- Pneumonia: 6.00%\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load best model\n",
        "model_path = \"outputs/models/best_tuned_model.joblib\"   # adjust path if needed\n",
        "print(f\"Using model file: {model_path}\")\n",
        "model = joblib.load(model_path)\n",
        "\n",
        "# Load dataset (use Training.csv to get all disease labels)\n",
        "df = pd.read_csv(\"Training.csv\")\n",
        "\n",
        "# Get feature columns and target classes\n",
        "feature_cols = df.columns[:-1]  # all except prognosis\n",
        "disease_names = df[\"prognosis\"].unique()  # all diseases\n",
        "\n",
        "def predict_from_symptoms(symptoms, top_n=3):\n",
        "    # Create input with all 0s\n",
        "    input_data = {col: 0 for col in feature_cols}\n",
        "    \n",
        "    # Mark provided symptoms as 1\n",
        "    for symptom in symptoms:\n",
        "        if symptom in input_data:\n",
        "            input_data[symptom] = 1\n",
        "    \n",
        "    # Convert to DataFrame\n",
        "    X_new = pd.DataFrame([input_data])\n",
        "\n",
        "    # Predict probabilities\n",
        "    if hasattr(model, \"predict_proba\"):\n",
        "        probs = model.predict_proba(X_new)[0]\n",
        "        # Get top n indices\n",
        "        top_indices = np.argsort(probs)[::-1][:top_n]\n",
        "        results = [(disease_names[i], probs[i]*100) for i in top_indices]\n",
        "        return results\n",
        "    else:\n",
        "        # Fallback: just return single prediction\n",
        "        prediction = model.predict(X_new)[0]\n",
        "        if isinstance(prediction, (int, float)) and prediction < len(disease_names):\n",
        "            return [(disease_names[int(prediction)], 100.0)]\n",
        "        return [(prediction, 100.0)]\n",
        "\n",
        "# Example usage:\n",
        "example_symptoms = [\"itching\", \"skin_rash\"]\n",
        "predictions = predict_from_symptoms(example_symptoms, top_n=3)\n",
        "\n",
        "print(\"Top Predictions:\")\n",
        "for disease, prob in predictions:\n",
        "    print(f\"- {disease}: {prob:.2f}%\")\n",
        "# -------------------------------------------------"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
